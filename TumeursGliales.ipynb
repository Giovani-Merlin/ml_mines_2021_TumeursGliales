{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a508092-0ed2-411d-a7f9-d32060ba24c9",
   "metadata": {},
   "source": [
    "# Mini-projet : Classification de tumeurs gliales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef50ae-8bbf-4da4-ae72-8f38881318ea",
   "metadata": {},
   "source": [
    "Les _gliomes_ ou _tumeurs gliales_ sont des tumeurs du glie, le tissu de soutien neuronal du cerveau. Elles sont classifiées en 4 grades anatomo-pathologiques, dont dépend la prise en charge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9571f5-f28c-4604-8496-a5b422f62d7b",
   "metadata": {},
   "source": [
    "Dans ce jeu de données, chaque observation est un gliome, décrit par l'expression de 4 434 gènes. L'expression d'un gène est une mesure de la quantité d'ARN correspondant à ce gène qui est présente dans la cellule. Schématiquement, l'ADN est transcrit en ARN, lequel est lui-même traduit en une protéine. Les protéines assurent une multitude de fonctions du vivant, mais mesurer leur quantité est difficile ; d'où l'intérêt d'utiliser les quantités d'ARN, bien que la correspondance ne soit pas immédiate. \n",
    "\n",
    "Chaque gliome de notre jeu de données est étiquetée en fonction de son grade. \n",
    "\n",
    "Le but de ce projet est de construire un classifieur qui détermine, sur la base de l'expression de ces 4 434 gènes, le grade d'un gliome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1970b2b-d686-4531-b771-6a5fd2d47ad2",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. Comparez les performances d'au moins deux algorithmes d'apprentissage sur ce problème de classification.\n",
    "\n",
    "__Attention :__\n",
    "* au _data leakage_ (ne pas utiliser les données sur lesquelles on évalue les modèles pour les entraîner ou prétraiter les données)\n",
    "* à la taille du jeu de données\n",
    "* au nombre de classes\n",
    "* à choisir une mesure de performance appropriée (justifiez votre choix)\n",
    "2. Identifiez, quand cela est possible, les gènes les plus importants pour les modèles que vous avez entraînés. S'agit-il des mêmes gènes\n",
    "* entre deux modèles obtenus grâce à un algorithme d'apprentissage différents ?\n",
    "* entre deux modèles obtenus en utilisant le même algorithme d'apprentissage sur des sous-échantillons différents des données ?\n",
    "\n",
    "N'oubliez pas de commenter et interpréter vos résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6274ace-a84a-4830-9872-92dfd3e54ede",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9d5f7c1-54a5-4772-9b7d-8799ea4c6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data_matrix = scipy.io.loadmat(\"gliome.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9dcb2008-d59a-4e35-a12d-ae7017f4c427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4434)\n"
     ]
    }
   ],
   "source": [
    "X = data_matrix['X']\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30f163fb-bb27-421e-a221-69d84791f721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "y = data_matrix['Y'][:, 0] \n",
    "print(y.shape)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "# pca = PCA(n_components=0.95)\n",
    "# pca.fit(X_std)\n",
    "# X_std = pca.transform(X_std)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obs, j'ai pas des connaissances de médicine mais les idées ici presentées peut-être modifiés facilement en aient un spécialiste en médecine.\n",
    "On va utiliser la metric \"accuracy\" parce que nos données sont bien stratifiés, c'est-à-dire, on a la même quantidate de classes pour chaque classe y_i.\n",
    "Cependant, on peut penser que la précision de la classe 4 est plus importante que la précision de la classe 1, parce que la classe 4 démande un chirurgie et on veut pas faire des opérations sans être nécessaire. D'autre, le recall de classe 1 est très importante aussi, parce que si on découvre le gliome à sont débout alors on peut le traiter et ênpecher son agravément."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.775000 (0.407224)\n",
      "SVM: 0.675000 (0.387298)\n",
      "RF: 0.775000 (0.428616)\n",
      "MLP: 0.600000 (0.428616)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict, StratifiedKFold\n",
    "from math import sqrt\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter=1000,solver=\"saga\"))) # saga = solver avec l1 regularization, ce qui est bien quand on a n << p. Elastic net serait le mieux à ce cas là probablement\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=random_state,max_features='sqrt')))\n",
    "models.append(('MLP', MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000)))\n",
    "\n",
    "results = {}\n",
    "names = []\n",
    "n_classes = 4\n",
    "for name, model in models:\n",
    "    # Manual Stratified K-Fold pour avoir plus de controle et tous les metriques\n",
    "    accuracy_list = []\n",
    "    class_results = defaultdict(lambda: defaultdict(list))\n",
    "    kf = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True).split(X_train, y_train)\n",
    "    for train_index, test_index in kf:\n",
    "\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        predict = model.predict(X_test_fold)\n",
    "        # Fonction facile pour faire la precision et recall (et f1) de chaque class\n",
    "        class_report = classification_report(y_test_fold, predict,zero_division=0,output_dict=True)\n",
    "        for i in range(n_classes):\n",
    "            class_results[i+1]['precision'].append(class_report[str(i+1)]['precision'])\n",
    "            class_results[i+1]['recall'].append(class_report[str(i+1)]['recall'])\n",
    "            class_results[i+1]['f1-score'].append(class_report[str(i+1)]['f1-score'])\n",
    "            class_results[i+1]['support'].append(class_report[str(i+1)]['support'])\n",
    "        accuracy_list.append(class_report['accuracy'])\n",
    "\n",
    "    for i in range(1,n_classes+1):\n",
    "        class_results[i]['precision'] = sum(class_results[i]['precision']) / len(class_results[i]['precision'])\n",
    "        class_results[i]['recall'] = sum(class_results[i]['recall']) / len(class_results[i]['recall'])\n",
    "        class_results[i]['f1-score'] = sum(class_results[i]['f1-score']) / len(class_results[i]['f1-score'])\n",
    "        # support au cass où on veut weighted\n",
    "    total_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "    std_accuracy = np.std(accuracy_list)\n",
    "\n",
    "    results[model] = {\"class_results\":class_results, \"accuracy\":total_accuracy, \"std_accuracy\":std_accuracy}\n",
    "    print('%s: %f (%f)' % (name, total_accuracy, sqrt(std_accuracy)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2c5d815ec1fe03f9c56d61fe27b8ffe51143b3b44a5b00413fd120b13315193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
